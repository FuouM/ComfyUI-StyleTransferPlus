{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_transform():\n",
    "    transform_list = []\n",
    "    transform_list.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"J:/AI/ComfyUI_windows_portable/ComfyUI/custom_nodes/ComfyUI-StyleTransferPlus/examples/cat.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 540)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_tf = test_transform()\n",
    "content = content_tf(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 540, 960])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1216, 0.1216, 0.1255,  ..., 0.4784, 0.4824, 0.4824],\n",
       "         [0.1216, 0.1216, 0.1255,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         [0.1216, 0.1216, 0.1216,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         ...,\n",
       "         [0.5608, 0.5686, 0.5451,  ..., 0.2627, 0.2902, 0.3098],\n",
       "         [0.5333, 0.5373, 0.5059,  ..., 0.2667, 0.2902, 0.3098],\n",
       "         [0.5373, 0.5412, 0.5137,  ..., 0.2667, 0.2902, 0.3098]],\n",
       "\n",
       "        [[0.1098, 0.1098, 0.1137,  ..., 0.5451, 0.5490, 0.5490],\n",
       "         [0.1098, 0.1098, 0.1137,  ..., 0.5490, 0.5490, 0.5490],\n",
       "         [0.1059, 0.1059, 0.1098,  ..., 0.5490, 0.5490, 0.5490],\n",
       "         ...,\n",
       "         [0.4706, 0.4980, 0.4745,  ..., 0.3882, 0.4196, 0.4392],\n",
       "         [0.4510, 0.4745, 0.4431,  ..., 0.3922, 0.4196, 0.4392],\n",
       "         [0.4706, 0.4863, 0.4510,  ..., 0.3922, 0.4196, 0.4392]],\n",
       "\n",
       "        [[0.0902, 0.0902, 0.0941,  ..., 0.3686, 0.3725, 0.3725],\n",
       "         [0.0902, 0.0902, 0.0941,  ..., 0.3725, 0.3725, 0.3725],\n",
       "         [0.0941, 0.0941, 0.0902,  ..., 0.3725, 0.3725, 0.3725],\n",
       "         ...,\n",
       "         [0.2980, 0.3098, 0.2784,  ..., 0.0902, 0.1098, 0.1216],\n",
       "         [0.2745, 0.2824, 0.2431,  ..., 0.0941, 0.1098, 0.1216],\n",
       "         [0.2902, 0.2941, 0.2510,  ..., 0.0941, 0.1098, 0.1216]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
